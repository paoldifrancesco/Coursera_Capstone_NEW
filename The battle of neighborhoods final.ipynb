{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# FINAL CAPSTONE PROJECT/ The battle of the neighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Addressing a business problem using a combination of structured problem solving, data analysis & machine learning."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## CONTENTS\n###  - Introduction\n### - Data collection and cleaning\n### - Methodology\n### - Results section\n###  - Discussion\n### - Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 1 Introduction/ Business Problem"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Paris is one of the most important cities in the world which attracts every year millions of tourists from all over the world. It is as well very famous for its excellent cuisine both national and international. One of the main actors in in international cousine is as well Italy which has exported all over the world its food culture starting from traditional Italian Pizza and spaghetti to many different regional food always appreciated.\n### Is there still, room for Italian food in Paris? \n### We think yes in general because quality is always appreciated, but even more for some types of foods that, being very popular in Italy, even for strangers visiting the country, still have a limited presence (compared to others) in some countries like France and specifically in Paris. \n### We are looking in this case to home-made Ice-cream. Wea re looking for several high-traffic locations not necessary in the very centre of the town. So we focus on that borough during our analysis. We define potential neighbourhood based on the number of potential competitors for ice-cream, pastries and in general frozen sweet food which are operating right in each neighbourhood. Paris has full potential but also it is a very challenging district to open a business because of high competition. New shops should be open where we can ensure that we have enough customers, where we are not so close to direct competitors or where, if we are close to others, we are sure to provide the best quality in order to attract as many customers as possible.\n### The scope of the project is to advise on the business strategies and execution roadmap on setting up an Italian Ice-cream shop in Paris. The initial business problem question is \u201cwhere is then better location in Paris to open one (or more) Italian home-made Ice-cream shop?\u201d.\n### The City of Paris is divided for administrative reasons into 20 main boroughs (arrondissments) for administrative purposes. Each of these administrative districts (or arrondissements) are officially divided into 4 quartiers.\n### You will find in this report a map showing Paris arrondissements and a map presenting Paris neighbourhoods. Within each of its boroughs, the neighbourhoods are providing the typical flavour of Paris with their own culture, locations and charme. The twenty arrondissements of Paris all have their own characteristics in terms of buildings, places to go out, restaurants, and in general aspects that can influence the success of an initiative to open a new activity.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2 Data Collecton and cleaning"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Paris has a total of 20 boroughs and 80 neighbourhoods. In order to segment the neighbourhoods and explore them, we will use sets of data available at data.govr.fr an open platform containing numerous sets of public French data.\n### we will use 2 data sets:\n### The first consists of the list of the 20 boroughs with their respective geographical coordinates:\n\n### https://www.data.gouv.fr/fr/datasets/r/0d3553c6-45c0-4b16-82be-5ef314437d3e\n\n### The second dataset consists of the 80 neighbourhoods with their respective geographical coordinates:\n\n### https://www.data.gouv.fr/fr/datasets/r/a3b31fdc-85dc-4aeb-94c6-a8b57aebef77\n\n### Merging these 2 datasets after having them cleaned we will have a final data frame with the 20 boroughs and the 4 neighbourhoods for each of them for a total of 80 with related geographicalcoordinates.\n### We will then use Folium to represent all these locations on a Paris Map and the Foursquare API to provision venues information for each neighbourhood.\n\n### With this additional information we will explore neighbourhood and we will cluster them in search of the best ones where to open our chain of home-made Ice cream."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## First we install all necessary libaries"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting folium\n  Downloading folium-0.12.1-py2.py3-none-any.whl (94 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 94 kB 5.1 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from folium) (2.25.1)\nCollecting branca>=0.3.0\n  Downloading branca-0.4.2-py3-none-any.whl (24 kB)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from folium) (1.19.2)\nRequirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from folium) (3.0.0)\nRequirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from jinja2>=2.9->folium) (2.0.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->folium) (2.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->folium) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->folium) (2021.5.30)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->folium) (3.0.4)\nInstalling collected packages: branca, folium\nSuccessfully installed branca-0.4.2 folium-0.12.1\nRequirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (4.9.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\nRequirement already satisfied: lxml in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (4.6.3)\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): - "
                }
            ],
            "source": "! pip install folium\n!pip install beautifulsoup4\n!pip install lxml\nimport requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n\n\nfrom IPython.display import display_html\nimport pandas as pd\nimport numpy as np\n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\nfrom bs4 import BeautifulSoup\nfrom sklearn.cluster import KMeans\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nprint('Folium installed')\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### We access the first file in repository Data.Gov.Fr, consisting of the list of the 20 boroughs with their respective geographical coordinates. we clean data and produce a simple dataframe with Borough Name and geographical data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Retrive url and transform in Pandas Dataframe\nurl =\"https://www.data.gouv.fr/fr/datasets/r/0d3553c6-45c0-4b16-82be-5ef314437d3e\"\ndf =pd.read_csv(url, sep=';')\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Reduce number of columns\ndf=df.drop(['n_sq_ar','n_sq_co','geom','surface','c_arinsee','l_ar','perimetre'], axis = 1)\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Rename columns\ndf = df.rename(columns={'c_ar': 'Borough_N','l_aroff': 'Borough', 'geom_x_y': 'Geo'})\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# We split the column \"Geo\" into 2 dofferent columns \"Lat\" and \"Long\"\ndf[\"Lat\"], df[\"long\"] = df[\"Geo\"].str.split(\",\", 2).str\ndf=df.drop(['Geo'], axis = 1)\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Ensure \"Lat\" and \"Long\" contain numeric data"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df[\"Lat\"] = pd.to_numeric(df[\"Lat\"])\ndf[\"long\"] = pd.to_numeric(df[\"long\"])\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Check data types\ndf.dtypes"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### We access the second file in repository Data.Gov.Fr, consisting of the list of the 20 neighboroughs with their respective geographical coordinates:we clean data and produce a simple dataframe with Neighborough Name and geographical data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# access file and transform in Pandas dathttps://eu-gb.dataplatform.cloud.ibm.com/data/jupyter2/runtimeenv2/v1/wdpx/service/notebook/conda2py37oce38ef488a3fbe41c7b2536e1346e781f9/dsxjpy/KRzo_DilmGMY_-cPmHimqg:eejrmOZ_R4vH62ZXIbCN9RwhiexgFzIT5Y6YGwmKlp86W2CZSwqugSQmZtIB5oTBhCHO9LM/container/notebooks/0ed9a070-f2f6-424d-bcfe-344c32ee3ca7?api=v2&project=38ef488a-3fbe-41c7-b253-6e1346e781f9#We-access-the-second-file-in-repository-Data.Gov.Fr,-consisting-of-the-list-of-the-20-neighboroughs-with-their-respective-geographical-coordinates:we-clean-data-and-produce-a-simple-dataframe-with-Neighborough-Name-and-geographical-data.aframe\nurl =\"https://www.data.gouv.fr/fr/datasets/r/a3b31fdc-85dc-4aeb-94c6-a8b57aebef77\"\ndf1=pd.read_csv(url, sep=';')\ndf1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Drop unnecessary columns\ndf1=df1.drop(['n_sq_ar','n_sq_qu','c_qu','c_quinsee','n_sq_ar','perimetre','surface','geom','perimetre'], axis = 1)\ndf1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# rename columns\ndf1 = df1.rename(columns={'c_ar': 'Borough_N','l_qu': 'Neighborhood'})\ndf1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# We split the column \"geom_x_y\" into 2 dofferent columns \"Latitude\" and \"Longitude\"\ndf1[\"Latitude\"], df1[\"Longitude\"] = df1[\"geom_x_y\"].str.split(\",\", 2).str\ndf1=df1.drop(['geom_x_y'], axis = 1)\ndf1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df1[\"Latitude\"] = pd.to_numeric(df1[\"Latitude\"])\ndf1[\"Longitude\"] = pd.to_numeric(df1[\"Longitude\"])\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Tables merge"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### We merge the 2 tables obtaiing a final One containing Boroughs, Neiborhoods and Geographical coordinates"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Merge based pon Borough_N\ndf_final= pd.merge(df,df1,on='Borough_N')\ndf_final=df_final.drop(['Lat','long'], axis = 1)\ndf_final.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Now we want to locate on map the Neighborhoods "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Using Geolocator we find Paris geographical coordinates and using Folium we create a map of Paris"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'Paris, FR'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Paris are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of Paris using latitude and longitude values\nmap_Paris = folium.Map(location=[latitude, longitude], zoom_start=12)\nmap_Paris\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Always using Folium we add Neigborhoods mark ups on the map"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add markers to map\nfor lat, lng, borough, neighborhood in zip(df_final['Latitude'],df_final['Longitude'], df_final['Borough'], df_final['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=10,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_Paris)\nmap_Paris\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Now we are ready to use Foursquare to explore venues in our nighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "###  We access foursquare"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = 'J0LNJZNREBEIANXYPUP4X2KLVLUTRJMG35NKAXOLSMYH1LDM' # your Foursquare ID\nCLIENT_SECRET = '4T5J2C4ZFSGYZUQFYT3OHVUE0GK41C2UB1CS3ZCRVU5HKFCR' # your Foursquare Secret\nVERSION = '20200605' # Foursquare API version\nLIMIT = 100 # A default Foursquare API limit value\nprint('Your credentials:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### We print the name and the coordinates of the first neighborhood in the table"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neighborhood_latitude = df_final.loc[9, 'Latitude'] # neighborhood latitude value\nneighborhood_longitude = df_final.loc[9, 'Longitude'] # neighborhood longitude value\n\nneighborhood_name = df_final.loc[9, 'Neighborhood'] # neighborhood name\n\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Get the top 100 venues that are in Archives within a radius of 500 meters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\n\n# get the result to a json file\nresults = requests.get(url).json()\nresults"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head(30)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Let's check the total number of venues by categories in the neighborhood Archives"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "nearby_venus_g=nearby_venues.groupby('categories').count()\n#nearby_venus_s=nearby_venus_g.sort_values('name')\nnearby_venus_s=nearby_venus_g.sort_values(by=['name'], ascending=False)\nnearby_venus_s"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Explore Neighborhoods in Paris"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Write the code to run the above function on each neighborhood and create a new dataframe called Paris_venues."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues = getNearbyVenues(names=df_final['Neighborhood'],\n                                   latitudes=df_final['Latitude'],\n                                   longitudes=df_final['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(Paris_venues.shape)\nParis_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Check how many venues were returned for each neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_tot=Paris_venues.groupby('Neighborhood').count()\nParis_venues_tot_s=Paris_venues_tot.sort_values(by=['Venue'], ascending=False)\nParis_venues_tot_s"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_tot_new= Paris_venues_tot_s[Paris_venues_tot_s['Venue'] > 50]\nParis_venues_tot_new.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques vanue categories.'.format(len(Paris_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_tot_new=Paris_venues_tot_new.drop(['Neighborhood Latitude','Neighborhood Longitude','Venue','Venue Latitude','Venue Longitude','Venue Category'], axis = 1)\nParis_venues_tot_new.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(\"The Venue Categories are\", Paris_venues['Venue Category'].unique())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Now we analyze each Neighborhood"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Create a new dataframe including only neigborhoods with more than 50 venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues = Paris_venues.merge(Paris_venues_tot_new, on='Neighborhood', how='inner')\n#Paris_venues.to_excel(r'C:\\Users\\Paold\\Export.xlsx', index = False)\n\nParis_venues.head()\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## We update DF_Final as well that will be needed for Clustering"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_final=df_final.merge(Paris_venues_tot_new, on='Neighborhood', how='inner')\ndf_final.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\nParis_onehot = pd.get_dummies(Paris_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nParis_onehot['Neighborhood'] = Paris_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [Paris_onehot.columns[-1]] + list(Paris_onehot.columns[:-1])\nParis_onehot = Paris_onehot[fixed_columns]\nParis_onehot.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_onehot.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_grouped = Paris_onehot.groupby('Neighborhood').mean().reset_index()\nParis_grouped.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## confirm the new size"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_grouped.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Paris_grouped.to_excel(r'C:\\Users\\Paold\\Export.xlsx', index = False)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Let's filter venues categories more important for us using presence of theatres museums clothing stores and others as indication of traffic"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_grouped1= Paris_grouped[['Neighborhood','Clothing Store','Cosmetics Shop','Bookstore','Record Shop','Gift Shop','Perfume Shop','Boutique','Shopping Mall','Ice Cream Shop']]\nParis_grouped1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Paris_grouped1.to_excel(r'C:\\Users\\Paold\\Export.xlsx', index = False)\n#Paris_grouped1.count('Ice Cream Shop')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Print each neighborhood along with the top 5 most common venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nfor hood in Paris_grouped1['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = Paris_grouped1[Paris_grouped1['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Put that into a pandas dataframe"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = Paris_grouped1['Neighborhood']\n\nfor ind in np.arange(Paris_grouped1.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(Paris_grouped1.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# get counts of Clothing Store in each Neighborhood\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Cluster Neighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kclusters = 5\nParis_grouped_clustering = Paris_grouped1.drop('Neighborhood', 1)\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Paris_grouped_clustering)\nkmeans.labels_[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nParis_merged = df_final\n\n#merge Paris_grouped with Paris_data to add latitude/longitude for each neighborhood\nParis_merged = Paris_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\nParis_merged.head(50) # check the last columns!"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_merged[\"Cluster Labels\"] = pd.to_numeric(Paris_merged[\"Cluster Labels\"])\nParis_merged['Cluster Labels'] = Paris_merged['Cluster Labels'].astype(int)\nParis_merged.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=13)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(Paris_merged['Latitude'], Paris_merged['Longitude'], Paris_merged['Neighborhood'], Paris_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=10,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\nmap_clusters\n       "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Examine clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Cluster 1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_merged.loc[Paris_merged['Cluster Labels'] == 0, Paris_merged.columns[[1,2] + list(range(5, Paris_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Cluster 2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_merged.loc[Paris_merged['Cluster Labels'] == 1, Paris_merged.columns[[1,2] + list(range(5, Paris_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Cluster 3"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_merged.loc[Paris_merged['Cluster Labels'] == 2, Paris_merged.columns[[1,2] + list(range(5, Paris_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Cluster 4"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_merged.loc[Paris_merged['Cluster Labels'] == 3, Paris_merged.columns[[1,2] + list(range(5, Paris_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Cluster 5"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_merged.loc[Paris_merged['Cluster Labels'] == 4, Paris_merged.columns[[1,2] + list(range(5, Paris_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##  We exclude immediately Cluster 1 and 2 and 5 where existing Ice cream shops are dominating all the categories of shops indicating traffic."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## As an example in Odeon we have 4 ice cream shops which is the second category after Hotels"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_N= Paris_venues[Paris_venues['Neighborhood'] == 'Od\u00e9on']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_FIN=Paris_venues_N.groupby('Venue Category').count()\nParis_venues_SORT=Paris_venues_FIN.sort_values(by=['Venue'], ascending=False)\nParis_venues_SORT"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## We exclude as well Cluster 3, too small, and We decide to focus on the Cluster Number 5 having the cluster 4 as second option"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Let' analyize Fisrt neigborhood Archives\t"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_N= Paris_venues[Paris_venues['Neighborhood'] == 'Archives']\nParis_venues_FIN=Paris_venues_N.groupby('Venue Category').count()\nParis_venues_SORT=Paris_venues_FIN.sort_values(by=['Venue'], ascending=False)\nParis_venues_SORT"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Archives looks a good potential for the scope of this analysis since it contais several venues indicating an high level of traffic only ONE ice cream Shop"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Same for Place Vendrome with a lot of venues indicating high traffic and one only ice creal shop"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_N= Paris_venues[Paris_venues['Neighborhood'] == 'Place-Vend\u00f4me']\nParis_venues_FIN=Paris_venues_N.groupby('Venue Category').count()\nParis_venues_SORT=Paris_venues_FIN.sort_values(by=['Venue'], ascending=False)\nParis_venues_SORT"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# let' check now Halles"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Paris_venues_N= Paris_venues[Paris_venues['Neighborhood'] == 'Halles']\nParis_venues_FIN=Paris_venues_N.groupby('Venue Category').count()\nParis_venues_SORT=Paris_venues_FIN.sort_values(by=['Venue'], ascending=False)\nParis_venues_SORT"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## This doesn' look a good location since there are 2 ice cream shops aalready existng and the other venues are above all restaurants, bars and coffee shops not bringing the traffic we are looking for."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# RESULTS"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## After clustering the data of the respective neighborhoods, and analyzing data, we have found several Neighborhoods in cluster 4 where it looks valuable to open an Italian Ice cream Shop like Archives, Enfants-Rouges Place-Vend\u00f4me, Saint-Germain"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# OBSERVATION AND RECCOMENDATION"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## The analysis should be continued to extract a certain number of locations and the final selection should be done and validated using additional data like the price per square meter located which gives as well the idea of the cost related to the opening of a shop in the specific Area.\n## The copleteness of Foursquare data for Paris is progressing but not yet at the level uf US, Canada or certain countries in Far east."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# CONCLUSION"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Destpite it can be improved, the analysis clearly shows that there is room for Italian Ice cram shops in Paris in areas where the level of traffic is more than sufficient to ensure a goog level of profitability.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}